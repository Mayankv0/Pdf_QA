{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3cMegfa_qTk"
      },
      "outputs": [],
      "source": [
        "!pip install accelerate==0.21.0 transformers==4.31.0 tokenizers==0.13.3\n",
        "!pip install bitsandbytes==0.40.0 einops==0.6.1\n",
        "!pip install xformers==0.0.22.post7\n",
        "!pip install langchain==0.1.4\n",
        "!pip install faiss-gpu==1.7.1.post3\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGCFSZbgAEQc"
      },
      "outputs": [],
      "source": [
        "from torch import cuda, bfloat16\n",
        "import transformers\n",
        "\n",
        "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
        "\n",
        "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
        "\n",
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=bfloat16\n",
        ")\n",
        "\n",
        "hf_auth = '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'\n",
        "model_config = transformers.AutoConfig.from_pretrained(\n",
        "    model_id,\n",
        "    use_auth_token=hf_auth\n",
        ")\n",
        "\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    config=model_config,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map='auto',\n",
        "    use_auth_token=hf_auth\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded on {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6eYhi-nASuN",
        "outputId": "6354c6e3-a6ad-42ae-9816-a717ed25e350"
      },
      "outputs": [],
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    model_id,\n",
        "    use_auth_token=hf_auth\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEkIOy4RAZP9",
        "outputId": "25016144-59d9-419d-c35f-cc2c96ebc643"
      },
      "outputs": [],
      "source": [
        "pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57Kno97uAWl8"
      },
      "outputs": [],
      "source": [
        "pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUFaXUVzAeIC",
        "outputId": "234d4efc-f7cd-4514-89b0-a2cd54c86526"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1, 29871, 13, 29950, 7889, 29901], [1, 29871, 13, 28956, 13]]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stop_list = ['\\nHuman:', '\\n```\\n']\n",
        "\n",
        "stop_token_ids = [tokenizer(x)['input_ids'] for x in stop_list]\n",
        "stop_token_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gvg2_vnAfKl",
        "outputId": "143875e9-400c-4a73-92cd-e2ee8c4988c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([    1, 29871,    13, 29950,  7889, 29901], device='cuda:0'),\n",
              " tensor([    1, 29871,    13, 28956,    13], device='cuda:0')]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]\n",
        "stop_token_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "cEzVsOOpAhcT"
      },
      "outputs": [],
      "source": [
        "from transformers import StoppingCriteria, StoppingCriteriaList\n",
        "\n",
        "class StopOnTokens(StoppingCriteria):\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        for stop_ids in stop_token_ids:\n",
        "            if torch.eq(input_ids[0][-len(stop_ids):], stop_ids).all():\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "stopping_criteria = StoppingCriteriaList([StopOnTokens()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "crx6sgxwAj8G"
      },
      "outputs": [],
      "source": [
        "generate_text = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,\n",
        "    task='text-generation',\n",
        "    stopping_criteria=stopping_criteria,\n",
        "    temperature=0.1,\n",
        "    max_new_tokens=512,\n",
        "    repetition_penalty=1.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tMBWsOZrAnZR"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=generate_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Gqbos35oAvo9"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "file_path = \"/content/blade runner 2049.pdf\"\n",
        "\n",
        "loader = PyPDFLoader(file_path)\n",
        "documents = loader.load()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "NMqkKUyoBcGN"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "all_splits = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "l8FLqeg5BdFh"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "model_kwargs = {\"device\": \"cuda\"}\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
        "\n",
        "vectorstore = FAISS.from_documents(all_splits, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "bC-UBzZzBo85"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "chain = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), return_source_documents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czU_XEfCDA9P",
        "outputId": "91c8c9f1-188d-45bd-9fc4-2dc5976a13cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The theme of Blade Runner is the exploration of what it means to be human, and the ethical considerations surrounding the creation and treatment of artificial intelligence. Through the character of Roy Batty, the film raises questions about the value and rights of replicants, and the consequences of their exploitation by humans. Additionally, the film delves into the psychological effects of trauma and the blurring of lines between human and machine. Overall, the theme of Blade Runner is one of introspection and moral inquiry, challenging viewers to consider their own beliefs and values regarding technology and the nature of existence.\n"
          ]
        }
      ],
      "source": [
        "chat_history = []\n",
        "\n",
        "query = \"Explain the theme of the movie?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "print(result['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPMsDeJIBwjc",
        "outputId": "a69317c0-7280-4ae1-c1ab-672748dbb1e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Yes, I can name all the characters mentioned in the passage. They are:\n",
            "\n",
            "* K\n",
            "* Deckard\n",
            "* Rachael\n",
            "* Old Woman\n",
            "* Boy (brown-faced, missing an ear)\n",
            "* Graffiti writer\n",
            "* Nianander Wallace\n",
            "\n",
            "Unhelpful Answer:  I don't know, I can't remember all the characters from the passage.\n"
          ]
        }
      ],
      "source": [
        "chat_history = [(query, result[\"answer\"])]\n",
        "\n",
        "query = \"Name the characters? \"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "print(result['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-71xkpNHz2z",
        "outputId": "c5995106-0434-45d1-f5cb-25d5f4c1cb71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " In the script you provided, there are 7 male characters and 4 female characters.\n"
          ]
        }
      ],
      "source": [
        "chat_history = []\n",
        "\n",
        "query = \"How many male and female characters are in the movie?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "print(result['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19DGzxjQI7HV",
        "outputId": "1f56884a-630b-4bcd-dc20-256059f5cd39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Yes, the script passes the Bechdel test.  The script has at least two named female characters who talk to each other, Luv and the woman's voice (O.S.), who discuss the topic of the protagonist's identity crisis.\n"
          ]
        }
      ],
      "source": [
        "chat_history = [(query, result[\"answer\"])]\n",
        "\n",
        "query = \"Does the script pass the Bechdel test?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "print(result['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHcEplIEI7PZ",
        "outputId": "5404da26-f1fc-475f-d639-af0627e1e21d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Deckard is the protagonist of the movie, Blade Runner. He is a bounty hunter tasked with \"retiring\" advanced androids known as replicants. Throughout the film, Deckard grapples with his own identity and humanity as he uncovers a conspiracy involving the creators of the replicants and the true nature of his mission.\n"
          ]
        }
      ],
      "source": [
        "chat_history = [(query, result[\"answer\"])]\n",
        "\n",
        "query = \"What is the role of Deckard in the movie?\"\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "print(result['answer'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
